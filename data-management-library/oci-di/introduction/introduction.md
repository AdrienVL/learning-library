# Introduction

## About this Workshop

This workshop introduces you to Oracle Cloud Infrastructure Data Integration and will give you a full tour of the service in a hands-on manner.
Oracle Cloud Infrastructure Data Integration is a fully managed, multi-tenant, serverless, native cloud service that helps you with common extract, load, and transform (ETL) tasks such as ingesting data from different sources, cleansing, transforming, and reshaping that data, and then efficiently loading it to target data sources on Oracle Cloud Infrastructure.
Administrators, data engineers, ETL developers, and operators are among the different types of data professionals who can use Oracle Cloud Infrastructure Data Integration and would benefit from this workshop.
We will first create a workspace in OCI Data Integration and connect to data assets. We will then create a data flow along with an integration and data loader task. We will create pipeline and a pipeline task and finally schedule to run it.  

Estimated Workshop Time: 2 Hours

### About Product/Technology
Modern organizations are embarking on their cloud-centric Artificial Intelligence (AI) and Analytics journeys. AI and Analytics initiatives need data integration to be successful. In maximizing value from data, you must decide how to transform and aggregate data as it is moved from sources to targets.
Oracle Cloud Infrastructure Data Integration is a key component of Oracle Cloud Infrastructure that provides a fully managed data integration offering. It is simple, intuitive, fast, scalable, resilient, secure, and managed by Oracle. Oracle Cloud Infrastructure Data Integration provides extract, load and transform (ETL) features include cleansing, reshaping, and transforming data as well as the associated lifecycle management to efficiently load a data warehouse, data mart or data lake to ensure the data is in the right place at the right time.
ETL developers will be able to load a data mart in minutes without coding, quickly discover and connect to popular databases and applications, and design & maintain complex ETL data flows effortlessly to load a data warehouse. Data engineers will be able to easily automate Apache Spark ETL data flows, prepare datasets quickly for Data Science projects, and stand up new data lake Services from cloud context and hybrid connectivity.

**Key use cases** include:
* Data Integration for Big Data, Data Lakes & Data Science – by efficiently loading and transforming data at scale into data lakes used for data science and analytics purposes
* Data Integration for Data Warehousing and Analytics – by efficiently loading and transforming data at scale into data marts and data warehouses (e.g. Autonomous Data Warehouse) used for analytics purposes
Key features
*	Visual, no-code design of ETL data flows
*	Data immersive user experience to boost productivity
*	Hybrid execution powered by Spark and SQL push-down capabilities
*	Rules-based data integration pattern to support schema evolution
*	Serverless execution, pay-as you go pricing model.

**Key business benefits**:
*	Easily transform and load data into data warehouse or Data Marts on Oracle Cloud Infrastructure
*	Gain user productivity with a no code user interface
*	Enterprise class solution with data exploration, data preparation, and data transformation functionality
*	Gain value from your data more quickly by having it in the right format, in the right place.


### Objectives

In this lab, you will:
* Create an OCI Data Integration Workspace and the necessary policies
* Create Data Assets in the Workspace
* Create a Data Flow. Data Loader task and Integration task
* Create a Pipeline task and publish task to Application
* Schedule and run the task


### Prerequisites

None, however:
* Familiarity with Database is desirable, but not required
* Some understanding of cloud and database terms is helpful
* Familiarity with Oracle Cloud Infrastructure (OCI) is helpful
* Familiarity with ETL concepts in helpful

## Learn More

*(optional - include links to docs, white papers, blogs, etc)*

* [URL text 1](http://docs.oracle.com)
* [URL text 2](http://docs.oracle.com)

## Acknowledgements
* **Author** - Theodora Cristea, Aditya Duvuri
* **Contributors** -  <Name, Group> -- optional
* **Last Updated By/Date** - <Name, Group, Month Year>
* **Workshop (or Lab) Expiry Date** - <Month Year> -- optional, use this when you are using a Pre-Authorized Request (PAR) URL to an object in Oracle Object Store.
